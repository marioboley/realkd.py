import pandas as pd
from pyparsing import java_style_comment
from realkd.rules import RuleBoostingEstimator, XGBRuleEstimator, logistic_loss

COLS = [
"Year",
"Quarter",
"Month",
"DayofMonth",
"DayOfWeek",
"FlightDate",
"Marketing_Airline_Network",
"Operated_or_Branded_Code_Share_Partners",
"DOT_ID_Marketing_Airline",
"IATA_Code_Marketing_Airline",
# "Flight_Number_Marketing_Airline",
"Originally_Scheduled_Code_Share_Airline",
# "DOT_ID_Originally_Scheduled_Code_Share_Airline",
"IATA_Code_Originally_Scheduled_Code_Share_Airline",
"Flight_Num_Originally_Scheduled_Code_Share_Airline",
"Operating_Airline",
"DOT_ID_Operating_Airline",
"IATA_Code_Operating_Airline",
"Tail_Number",
"Flight_Number_Operating_Airline",
"OriginAirportID",
"OriginAirportSeqID",
"OriginCityMarketID",
"Origin",
"OriginCityName",
"OriginState",
"OriginStateFips",
"OriginStateName",
"OriginWac",
"DestAirportID",
"DestAirportSeqID",
"DestCityMarketID",
"Dest",
"DestCityName",
"DestState",
"DestStateFips",
"DestStateName",
"DestWac",
"CRSDepTime",
"DepTime",
"DepDelay",
"DepDelayMinutes",
"DepDel15",
"DepartureDelayGroups",
"DepTimeBlk",
"TaxiOut",#46
# "WheelsOff",
"WheelsOn", 
"TaxiIn",
"CRSArrTime",
# "ArrTime",
# "ArrDelay",
# "ArrDelayMinutes",
"ArrDel15",
# "ArrivalDelayGroups",
"ArrTimeBlk",
"Cancelled",
"CancellationCode",
# "Diverted",
"CRSElapsedTime",
"ActualElapsedTime",
"AirTime",
"Flights",
"Distance",
"DistanceGroup",
"CarrierDelay",
"WeatherDelay",
"NASDelay",
"SecurityDelay",
"LateAircraftDelay",
"FirstDepTime",
"TotalAddGTime",
"LongestAddGTime",
"DivAirportLandings",
"DivReachedDest",
"DivActualElapsedTime",
"DivArrDelay",
"DivDistance",
"Div1Airport",
"Div1AirportID",
"Div1AirportSeqID",
"Div1WheelsOn",
"Div1TotalGTime",
# "Div1LongestGTime", #78
"Div1WheelsOff",
"Div1TailNum",
"Div2Airport",
"Div2AirportID",
"Div2AirportSeqID",
"Div2WheelsOn",
# "Div2TotalGTime",
# "Div2LongestGTime",
"Div2WheelsOff",
"Div2TailNum",
"Div3Airport",
"Div3AirportID",
"Div3AirportSeqID",
"Div3WheelsOn",
# "Div3TotalGTime",
"Div3LongestGTime",
"Div3WheelsOff",
"Div3TailNum",
"Div4Airport",
"Div4AirportID",
"Div4AirportSeqID",
"Div4WheelsOn",
"Div4TotalGTime",
"Div4LongestGTime",
"Div4WheelsOff",
"Div4TailNum",
"Div5Airport",
"Div5AirportID",
"Div5AirportSeqID",
"Div5WheelsOn",
"Div5TotalGTime",
"Div5LongestGTime",
"Div5WheelsOff",
"Div5TailNum",
"Duplicate"]
if(False):
    dataset = pd.read_csv('datasets/titanic/train.csv')
    y = dataset.Survived
    dataset.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin', 'Survived'], inplace=True)
else:
    # dataset = pd.read_csv('archive/flight_data_2018_to_2022.csv', usecols=COLS)
    dataset = pd.read_csv('archive/flight_data_2018_to_2022.csv', usecols=['Quarter', 'Month', 'Dest', 'Origin', 'Cancelled', 'Distance'])
    # dataset = dataset.sample(n=999999)
    y = dataset.Cancelled
    dataset.drop(columns=['Cancelled'], inplace=True)


re = RuleBoostingEstimator(base_learner=XGBRuleEstimator(loss=logistic_loss))
re.fit(dataset, y.replace(0, -1))
print(re.rules_)
